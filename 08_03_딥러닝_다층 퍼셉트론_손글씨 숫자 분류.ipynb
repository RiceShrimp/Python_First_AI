{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[50000: 60000]\n",
    "x_train = x_train[: 50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = y_train[50000: 60000]\n",
    "y_train = y_train[0:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "[5 0 4 1 9 2 1 3 1]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0][8])\n",
    "print(y_train[0:9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(50000, 784)\n",
    "x_val = x_val.reshape(10000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "gray_scale = 255\n",
    "x_train /= gray_scale\n",
    "x_val /= gray_scale\n",
    "x_test /= gray_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x):\n",
    "    w1 = tf.Variable(tf.random_uniform([784, 256]))\n",
    "    b1 = tf.Variable(tf.zeros([256]))\n",
    "    h1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "    \n",
    "    w2 = tf.Variable(tf.random_uniform([256, 128]))\n",
    "    b2 = tf.Variable(tf.zeros([128]))\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n",
    "    \n",
    "    h2_drop = tf.nn.dropout(h2, keep_prob)\n",
    "    \n",
    "    w3 = tf.Variable(tf.random_uniform([128, 10]))\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "    logits = tf.matmul(h2_drop, w3) + b3\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-99d6d68c6b05>:10: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "logits = mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits= logits, labels= y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = tf.train.AdamOptimizer(learning_rate= 0.01).minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "epoch_cnt = 300\n",
    "batch_size = 1000\n",
    "iteration = len(x_train) // batch_size\n",
    "\n",
    "earlystop_threshold = 5\n",
    "earlystop_cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train acc: 0.1708, val acc: 0.1738\n",
      "epoch: 1, train acc: 0.49194, val acc: 0.5047\n",
      "epoch: 2, train acc: 0.5828, val acc: 0.6021\n",
      "epoch: 3, train acc: 0.63694, val acc: 0.6571\n",
      "epoch: 4, train acc: 0.67022, val acc: 0.6881\n",
      "epoch: 5, train acc: 0.69594, val acc: 0.7114\n",
      "epoch: 6, train acc: 0.71912, val acc: 0.7371\n",
      "epoch: 7, train acc: 0.7414, val acc: 0.7564\n",
      "epoch: 8, train acc: 0.76134, val acc: 0.7754\n",
      "epoch: 9, train acc: 0.77972, val acc: 0.791\n",
      "epoch: 10, train acc: 0.79532, val acc: 0.8074\n",
      "epoch: 11, train acc: 0.81086, val acc: 0.8229\n",
      "epoch: 12, train acc: 0.82484, val acc: 0.8335\n",
      "epoch: 13, train acc: 0.83546, val acc: 0.8428\n",
      "epoch: 14, train acc: 0.84606, val acc: 0.8514\n",
      "epoch: 15, train acc: 0.85404, val acc: 0.8577\n",
      "epoch: 16, train acc: 0.86364, val acc: 0.8654\n",
      "epoch: 17, train acc: 0.87146, val acc: 0.8728\n",
      "epoch: 18, train acc: 0.8789, val acc: 0.8794\n",
      "epoch: 19, train acc: 0.88468, val acc: 0.8843\n",
      "epoch: 20, train acc: 0.891, val acc: 0.8895\n",
      "epoch: 21, train acc: 0.89588, val acc: 0.8929\n",
      "epoch: 22, train acc: 0.89996, val acc: 0.8964\n",
      "epoch: 23, train acc: 0.90306, val acc: 0.9003\n",
      "epoch: 24, train acc: 0.90652, val acc: 0.9031\n",
      "epoch: 25, train acc: 0.90918, val acc: 0.9047\n",
      "epoch: 26, train acc: 0.91202, val acc: 0.9074\n",
      "epoch: 27, train acc: 0.91456, val acc: 0.9089\n",
      "epoch: 28, train acc: 0.91686, val acc: 0.9103\n",
      "epoch: 29, train acc: 0.92104, val acc: 0.9134\n",
      "epoch: 30, train acc: 0.92204, val acc: 0.9145\n",
      "epoch: 31, train acc: 0.924, val acc: 0.9161\n",
      "epoch: 32, train acc: 0.92628, val acc: 0.9184\n",
      "epoch: 33, train acc: 0.9287, val acc: 0.9199\n",
      "epoch: 34, train acc: 0.9297, val acc: 0.9201\n",
      "epoch: 35, train acc: 0.93184, val acc: 0.9235\n",
      "epoch: 36, train acc: 0.9335, val acc: 0.9242\n",
      "epoch: 37, train acc: 0.93498, val acc: 0.9254\n",
      "epoch: 38, train acc: 0.93658, val acc: 0.9256\n",
      "epoch: 39, train acc: 0.93736, val acc: 0.9262\n",
      "epoch: 40, train acc: 0.93966, val acc: 0.9293\n",
      "epoch: 41, train acc: 0.94004, val acc: 0.9283\n",
      "overfitting warning: 0\n",
      "epoch: 42, train acc: 0.94236, val acc: 0.9302\n",
      "epoch: 43, train acc: 0.94402, val acc: 0.9314\n",
      "epoch: 44, train acc: 0.94468, val acc: 0.9326\n",
      "epoch: 45, train acc: 0.94588, val acc: 0.9317\n",
      "overfitting warning: 0\n",
      "epoch: 46, train acc: 0.94732, val acc: 0.9329\n",
      "epoch: 47, train acc: 0.94798, val acc: 0.9333\n",
      "epoch: 48, train acc: 0.94954, val acc: 0.9342\n",
      "epoch: 49, train acc: 0.95058, val acc: 0.9351\n",
      "epoch: 50, train acc: 0.95144, val acc: 0.936\n",
      "epoch: 51, train acc: 0.95184, val acc: 0.9354\n",
      "overfitting warning: 0\n",
      "epoch: 52, train acc: 0.95238, val acc: 0.9346\n",
      "overfitting warning: 1\n",
      "epoch: 53, train acc: 0.95378, val acc: 0.9349\n",
      "overfitting warning: 2\n",
      "epoch: 54, train acc: 0.95454, val acc: 0.9358\n",
      "overfitting warning: 3\n",
      "epoch: 55, train acc: 0.9557, val acc: 0.9376\n",
      "epoch: 56, train acc: 0.95664, val acc: 0.9384\n",
      "epoch: 57, train acc: 0.95684, val acc: 0.9381\n",
      "overfitting warning: 0\n",
      "epoch: 58, train acc: 0.95776, val acc: 0.9383\n",
      "overfitting warning: 1\n",
      "epoch: 59, train acc: 0.95746, val acc: 0.9394\n",
      "epoch: 60, train acc: 0.95896, val acc: 0.9396\n",
      "epoch: 61, train acc: 0.96036, val acc: 0.9406\n",
      "epoch: 62, train acc: 0.96126, val acc: 0.9396\n",
      "overfitting warning: 0\n",
      "epoch: 63, train acc: 0.96152, val acc: 0.9408\n",
      "epoch: 64, train acc: 0.96196, val acc: 0.9418\n",
      "epoch: 65, train acc: 0.96328, val acc: 0.9402\n",
      "overfitting warning: 0\n",
      "epoch: 66, train acc: 0.96428, val acc: 0.942\n",
      "epoch: 67, train acc: 0.96556, val acc: 0.9424\n",
      "epoch: 68, train acc: 0.96576, val acc: 0.9438\n",
      "epoch: 69, train acc: 0.96624, val acc: 0.9426\n",
      "overfitting warning: 0\n",
      "epoch: 70, train acc: 0.96682, val acc: 0.9438\n",
      "epoch: 71, train acc: 0.96768, val acc: 0.9457\n",
      "epoch: 72, train acc: 0.96806, val acc: 0.9444\n",
      "overfitting warning: 0\n",
      "epoch: 73, train acc: 0.96842, val acc: 0.9442\n",
      "overfitting warning: 1\n",
      "epoch: 74, train acc: 0.96808, val acc: 0.9448\n",
      "epoch: 75, train acc: 0.96932, val acc: 0.9461\n",
      "epoch: 76, train acc: 0.97018, val acc: 0.9472\n",
      "epoch: 77, train acc: 0.9711, val acc: 0.9461\n",
      "overfitting warning: 0\n",
      "epoch: 78, train acc: 0.97116, val acc: 0.9473\n",
      "epoch: 79, train acc: 0.9713, val acc: 0.9475\n",
      "epoch: 80, train acc: 0.97134, val acc: 0.9471\n",
      "overfitting warning: 0\n",
      "epoch: 81, train acc: 0.97204, val acc: 0.9468\n",
      "overfitting warning: 1\n",
      "epoch: 82, train acc: 0.97274, val acc: 0.9474\n",
      "overfitting warning: 2\n",
      "epoch: 83, train acc: 0.97344, val acc: 0.9469\n",
      "overfitting warning: 3\n",
      "epoch: 84, train acc: 0.9743, val acc: 0.9472\n",
      "overfitting warning: 4\n",
      "epoch: 85, train acc: 0.9739, val acc: 0.9473\n",
      "epoch: 86, train acc: 0.97428, val acc: 0.9467\n",
      "overfitting warning: 0\n",
      "epoch: 87, train acc: 0.9753, val acc: 0.9478\n",
      "epoch: 88, train acc: 0.97444, val acc: 0.9496\n",
      "epoch: 89, train acc: 0.97506, val acc: 0.9488\n",
      "overfitting warning: 0\n",
      "epoch: 90, train acc: 0.97624, val acc: 0.9494\n",
      "overfitting warning: 1\n",
      "epoch: 91, train acc: 0.97568, val acc: 0.9486\n",
      "epoch: 92, train acc: 0.97638, val acc: 0.9496\n",
      "epoch: 93, train acc: 0.97774, val acc: 0.9518\n",
      "epoch: 94, train acc: 0.9784, val acc: 0.9503\n",
      "overfitting warning: 0\n",
      "epoch: 95, train acc: 0.97776, val acc: 0.95\n",
      "epoch: 96, train acc: 0.97828, val acc: 0.9504\n",
      "overfitting warning: 0\n",
      "epoch: 97, train acc: 0.97844, val acc: 0.9503\n",
      "overfitting warning: 1\n",
      "epoch: 98, train acc: 0.97748, val acc: 0.9484\n",
      "epoch: 99, train acc: 0.97934, val acc: 0.9495\n",
      "overfitting warning: 0\n",
      "epoch: 100, train acc: 0.97842, val acc: 0.9494\n",
      "epoch: 101, train acc: 0.97898, val acc: 0.9499\n",
      "overfitting warning: 0\n",
      "epoch: 102, train acc: 0.9794, val acc: 0.9522\n",
      "epoch: 103, train acc: 0.9794, val acc: 0.9511\n",
      "epoch: 104, train acc: 0.97942, val acc: 0.9513\n",
      "overfitting warning: 0\n",
      "epoch: 105, train acc: 0.9803, val acc: 0.9498\n",
      "overfitting warning: 1\n",
      "epoch: 106, train acc: 0.98022, val acc: 0.9507\n",
      "epoch: 107, train acc: 0.98012, val acc: 0.9517\n",
      "epoch: 108, train acc: 0.9784, val acc: 0.9486\n",
      "epoch: 109, train acc: 0.98096, val acc: 0.9514\n",
      "overfitting warning: 0\n",
      "epoch: 110, train acc: 0.98114, val acc: 0.9511\n",
      "overfitting warning: 1\n",
      "epoch: 111, train acc: 0.9818, val acc: 0.9526\n",
      "epoch: 112, train acc: 0.98086, val acc: 0.9535\n",
      "epoch: 113, train acc: 0.98276, val acc: 0.954\n",
      "epoch: 114, train acc: 0.98252, val acc: 0.9542\n",
      "epoch: 115, train acc: 0.98282, val acc: 0.9535\n",
      "overfitting warning: 0\n",
      "epoch: 116, train acc: 0.98358, val acc: 0.9556\n",
      "epoch: 117, train acc: 0.98412, val acc: 0.954\n",
      "overfitting warning: 0\n",
      "epoch: 118, train acc: 0.98478, val acc: 0.9537\n",
      "overfitting warning: 1\n",
      "epoch: 119, train acc: 0.9835, val acc: 0.9544\n",
      "epoch: 120, train acc: 0.98172, val acc: 0.9512\n",
      "epoch: 121, train acc: 0.98156, val acc: 0.951\n",
      "epoch: 122, train acc: 0.98054, val acc: 0.9496\n",
      "epoch: 123, train acc: 0.98412, val acc: 0.9521\n",
      "overfitting warning: 0\n",
      "epoch: 124, train acc: 0.98306, val acc: 0.953\n",
      "epoch: 125, train acc: 0.98048, val acc: 0.9504\n",
      "epoch: 126, train acc: 0.97992, val acc: 0.9501\n",
      "epoch: 127, train acc: 0.98112, val acc: 0.9491\n",
      "overfitting warning: 0\n",
      "epoch: 128, train acc: 0.98424, val acc: 0.9549\n",
      "overfitting warning: 1\n",
      "epoch: 129, train acc: 0.98494, val acc: 0.955\n",
      "overfitting warning: 2\n",
      "epoch: 130, train acc: 0.9844, val acc: 0.953\n",
      "epoch: 131, train acc: 0.98488, val acc: 0.9549\n",
      "overfitting warning: 0\n",
      "epoch: 132, train acc: 0.98606, val acc: 0.955\n",
      "overfitting warning: 1\n",
      "epoch: 133, train acc: 0.98516, val acc: 0.955\n",
      "epoch: 134, train acc: 0.98732, val acc: 0.9561\n",
      "epoch: 135, train acc: 0.98526, val acc: 0.9531\n",
      "epoch: 136, train acc: 0.98684, val acc: 0.9546\n",
      "overfitting warning: 0\n",
      "epoch: 137, train acc: 0.98762, val acc: 0.9562\n",
      "epoch: 138, train acc: 0.98664, val acc: 0.9568\n",
      "epoch: 139, train acc: 0.98634, val acc: 0.9549\n",
      "epoch: 140, train acc: 0.98774, val acc: 0.9564\n",
      "overfitting warning: 0\n",
      "epoch: 141, train acc: 0.98662, val acc: 0.9562\n",
      "epoch: 142, train acc: 0.98298, val acc: 0.9527\n",
      "epoch: 143, train acc: 0.98786, val acc: 0.9572\n",
      "epoch: 144, train acc: 0.98484, val acc: 0.9537\n",
      "epoch: 145, train acc: 0.98626, val acc: 0.958\n",
      "epoch: 146, train acc: 0.98636, val acc: 0.9573\n",
      "overfitting warning: 0\n",
      "epoch: 147, train acc: 0.98758, val acc: 0.9579\n",
      "overfitting warning: 1\n",
      "epoch: 148, train acc: 0.98558, val acc: 0.9559\n",
      "epoch: 149, train acc: 0.9856, val acc: 0.9542\n",
      "overfitting warning: 0\n",
      "epoch: 150, train acc: 0.98688, val acc: 0.9567\n",
      "overfitting warning: 1\n",
      "epoch: 151, train acc: 0.98322, val acc: 0.9529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 152, train acc: 0.98412, val acc: 0.9539\n",
      "overfitting warning: 0\n",
      "epoch: 153, train acc: 0.9845, val acc: 0.956\n",
      "overfitting warning: 1\n",
      "epoch: 154, train acc: 0.9859, val acc: 0.955\n",
      "overfitting warning: 2\n",
      "epoch: 155, train acc: 0.98804, val acc: 0.9542\n",
      "overfitting warning: 3\n",
      "epoch: 156, train acc: 0.9896, val acc: 0.9571\n",
      "overfitting warning: 4\n",
      "epoch: 157, train acc: 0.98918, val acc: 0.9575\n",
      "epoch: 158, train acc: 0.99068, val acc: 0.9576\n",
      "overfitting warning: 0\n",
      "epoch: 159, train acc: 0.98814, val acc: 0.9556\n",
      "epoch: 160, train acc: 0.98784, val acc: 0.9556\n",
      "epoch: 161, train acc: 0.98932, val acc: 0.9555\n",
      "overfitting warning: 0\n",
      "epoch: 162, train acc: 0.99026, val acc: 0.9573\n",
      "overfitting warning: 1\n",
      "epoch: 163, train acc: 0.9899, val acc: 0.9574\n",
      "epoch: 164, train acc: 0.98946, val acc: 0.9584\n",
      "epoch: 165, train acc: 0.9909, val acc: 0.9591\n",
      "epoch: 166, train acc: 0.99062, val acc: 0.9596\n",
      "epoch: 167, train acc: 0.99228, val acc: 0.9598\n",
      "epoch: 168, train acc: 0.9922, val acc: 0.962\n",
      "epoch: 169, train acc: 0.99124, val acc: 0.9601\n",
      "overfitting warning: 0\n",
      "epoch: 170, train acc: 0.99204, val acc: 0.9622\n",
      "epoch: 171, train acc: 0.99188, val acc: 0.9598\n",
      "overfitting warning: 0\n",
      "epoch: 172, train acc: 0.99226, val acc: 0.9606\n",
      "overfitting warning: 1\n",
      "epoch: 173, train acc: 0.99096, val acc: 0.9591\n",
      "overfitting warning: 2\n",
      "epoch: 174, train acc: 0.99138, val acc: 0.9613\n",
      "overfitting warning: 3\n",
      "epoch: 175, train acc: 0.99218, val acc: 0.9622\n",
      "epoch: 176, train acc: 0.99254, val acc: 0.963\n",
      "epoch: 177, train acc: 0.99154, val acc: 0.9616\n",
      "overfitting warning: 0\n",
      "epoch: 178, train acc: 0.99156, val acc: 0.962\n",
      "overfitting warning: 1\n",
      "epoch: 179, train acc: 0.99234, val acc: 0.9612\n",
      "overfitting warning: 2\n",
      "epoch: 180, train acc: 0.99254, val acc: 0.9618\n",
      "overfitting warning: 3\n",
      "epoch: 181, train acc: 0.9929, val acc: 0.9599\n",
      "overfitting warning: 4\n",
      "epoch: 182, train acc: 0.99358, val acc: 0.9619\n",
      "early stopped on 182\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    prev_train_acc = 0.0\n",
    "    max_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(epoch_cnt):\n",
    "        avg_loss = 0.\n",
    "        start = 0; end = batch_size\n",
    "        \n",
    "        for i in range(iteration):\n",
    "            _, loss = sess.run([train_op, loss_op], \n",
    "                               feed_dict={x: x_train[start: end], \n",
    "                                          y: y_train[start: end], \n",
    "                                          keep_prob: 0.9})\n",
    "            start += batch_size; end += batch_size\n",
    "            # Compute train average loss\n",
    "            avg_loss += loss / iteration\n",
    "            \n",
    "        # Validate model\n",
    "        preds = tf.nn.softmax(logits)  # Apply softmax to logits\n",
    "        correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y, 1))\n",
    "        # Calculate accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        # train accuracy\n",
    "        cur_train_acc = accuracy.eval({x: x_train, y: y_train,keep_prob: 1.0})\n",
    "        # validation accuarcy\n",
    "        cur_val_acc = accuracy.eval({x: x_val, y: y_val, keep_prob: 1.0})\n",
    "        # validation loss\n",
    "        cur_val_loss = loss_op.eval({x: x_val, y: y_val,keep_prob: 1.0})\n",
    "        \n",
    "        print(\"epoch: \"+str(epoch)+\n",
    "              \", train acc: \" + str(cur_train_acc) +\n",
    "              \", val acc: \" + str(cur_val_acc) )\n",
    "              #', train loss: '+str(avg_loss)+\n",
    "              #', val loss: '+str(cur_val_loss))\n",
    "        \n",
    "        if cur_val_acc < max_val_acc:\n",
    "            if cur_train_acc > prev_train_acc or cur_train_acc > 0.99:\n",
    "                if earlystop_cnt == earlystop_threshold:\n",
    "                    print(\"early stopped on \"+str(epoch))\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"overfitting warning: \"+str(earlystop_cnt))\n",
    "                    earlystop_cnt += 1\n",
    "            else:\n",
    "                earlystop_cnt = 0\n",
    "        else:\n",
    "            earlystop_cnt = 0\n",
    "            max_val_acc = cur_val_acc\n",
    "            # Save the variables to file.\n",
    "            save_path = saver.save(sess, \"model/model.ckpt\")\n",
    "        prev_train_acc = cur_train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Q\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from model/model.ckpt\n",
      "[Test Accuracy] :  0.958\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model/model.ckpt')\n",
    "    correct_predicion = tf.equal(tf.argmax(preds, 1), tf.argmax(y, 1))\n",
    "    \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "    print('[Test Accuracy] : ', accuracy.eval({x: x_test, y: y_test, keep_prob: 1.0}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
